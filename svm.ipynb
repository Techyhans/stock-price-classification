{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "spacy_eng = en_core_web_sm.load()\n",
    "data = os.path.join(os.getcwd(),'data_final.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# To map each word to a index, convert string to numerical value\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold):\n",
    "        # freq_threshold check the freq word in text, if 1 , may not important to us\n",
    "        # <UNK> if the word freq appear is less than threshold, it will map to <UNK>\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "\n",
    "    # tokenize the caption [I love coffee] -> [\"i\",\"love\",\"coffee\"]\n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "    # build vocab\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        # count each caption how many times a specific word repeated\n",
    "        # if over the threshold we will include it, else ignore it\n",
    "        frequencies = {}\n",
    "        # start with index 4 because we have include the tagging\n",
    "        idx = 4\n",
    "\n",
    "        #self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\", 4: \"i\"}\n",
    "        #self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3, \"i\":4}\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer_eng(sentence):\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 1\n",
    "\n",
    "                else:\n",
    "                    frequencies[word] += 1\n",
    "                # if the word frequence is we want,(we just need to append 1 times only)\n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1 # store word to next index\n",
    "\n",
    "    # convert text into number\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer_eng(text)\n",
    "\n",
    "\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] # if word is not in library, <UNK>\n",
    "            for token in tokenized_text\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, captions_file, freq_threshold=5):\n",
    "        self.df = pd.read_csv(captions_file)\n",
    "        self.df = self.df.loc[self.df['Price movement'].isin([\"Up\", \"Down\"])]\n",
    "\n",
    "        # Get img, caption columns\n",
    "        self.captions = self.df[\"Headline\"]\n",
    "        self.results = self.df[\"Price movement\"]\n",
    "\n",
    "        # Initialize vocabulary and build vocab\n",
    "        self.vocab = Vocabulary(freq_threshold)\n",
    "        # Send all the caption as list\n",
    "        self.vocab.build_vocabulary(self.captions.tolist())\n",
    "\n",
    "        vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "\n",
    "        self.Y = []\n",
    "        for result in self.results:\n",
    "            tokenizer = {\"Down\": 0, \"Up\": 1}\n",
    "            self.Y.append(tokenizer[result])\n",
    "\n",
    "        self.captions_train, self.captions_test, self.y_train, self.y_test = train_test_split(self.captions, self.Y,test_size=0.2)\n",
    "\n",
    "        self.X_train = vectorizer.fit_transform(self.captions_train)\n",
    "        self.X_test = vectorizer.transform(self.captions_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = Dataset(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 7.314695s; Prediction time: 1.466022s\n",
      "Accuracy:  0.5681265206812652\n",
      "Up:  {'precision': 0.5883458646616542, 'recall': 0.6971046770601337, 'f1-score': 0.6381243628950052, 'support': 449}\n",
      "Down:  {'precision': 0.5310344827586206, 'recall': 0.4128686327077748, 'f1-score': 0.46455505279034687, 'support': 373}\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(dataset.X_train, dataset.y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(dataset.X_test)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "\n",
    "report = classification_report(dataset.y_test, prediction_linear, output_dict=True)\n",
    "\n",
    "print('Accuracy: ', report['accuracy'])\n",
    "print('Up: ', report['1'])\n",
    "print('Down: ', report['0'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}