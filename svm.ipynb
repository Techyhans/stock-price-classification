{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "spacy_eng = en_core_web_sm.load()\n",
    "data = os.path.join(os.getcwd(),'data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# To map each word to a index, convert string to numerical value\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold):\n",
    "        # freq_threshold check the freq word in text, if 1 , may not important to us\n",
    "        # <UNK> if the word freq appear is less than threshold, it will map to <UNK>\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "\n",
    "    # tokenize the caption [I love coffee] -> [\"i\",\"love\",\"coffee\"]\n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "    # build vocab\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        # count each caption how many times a specific word repeated\n",
    "        # if over the threshold we will include it, else ignore it\n",
    "        frequencies = {}\n",
    "        # start with index 4 because we have include the tagging\n",
    "        idx = 4\n",
    "\n",
    "        #self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\", 4: \"i\"}\n",
    "        #self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3, \"i\":4}\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer_eng(sentence):\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 1\n",
    "\n",
    "                else:\n",
    "                    frequencies[word] += 1\n",
    "                # if the word frequence is we want,(we just need to append 1 times only)\n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1 # store word to next index\n",
    "\n",
    "    # convert text into number\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer_eng(text)\n",
    "\n",
    "\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] # if word is not in library, <UNK>\n",
    "            for token in tokenized_text\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, captions_file, freq_threshold=5):\n",
    "        self.df = pd.read_csv(captions_file)\n",
    "\n",
    "        # Get img, caption columns\n",
    "        self.captions = self.df[\"Headline\"]\n",
    "        self.results = self.df[\"Price movement\"]\n",
    "\n",
    "        # Initialize vocabulary and build vocab\n",
    "        self.vocab = Vocabulary(freq_threshold)\n",
    "        # Send all the caption as list\n",
    "        self.vocab.build_vocabulary(self.captions.tolist())\n",
    "\n",
    "        self.X = pd.DataFrame()\n",
    "        for caption in self.captions:\n",
    "            numericalized_caption = [self.vocab.stoi[\"<SOS>\"]]\n",
    "            numericalized_caption += self.vocab.numericalize(caption)\n",
    "            numericalized_caption.append(self.vocab.stoi[\"<EOS>\"])\n",
    "            self.X.append(np.array(numericalized_caption))\n",
    "\n",
    "        self.Y = pd.DataFrame()\n",
    "        for result in self.results:\n",
    "            tokenizer = {\"Down\": 0, \"Up\": 1}\n",
    "            self.Y.append(tokenizer[result])\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.Y,test_size=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "dataset = Dataset(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           EVENING 5: Five things you need to know today\n",
      "1       KLCI retreats on profit taking on final tradin...\n",
      "2       Cover Story: Delicate balancing act in a tough...\n",
      "3                                            重量级股遭抛售 马股走低\n",
      "4                                         2020年马股的最大赢家和输家\n",
      "                              ...                        \n",
      "5636               Market rises for the third day of 2010\n",
      "5637         Glove makers rally on more upside for sector\n",
      "5638       Tanjong,CIMB, Axiata push FBM KLCI above 1,290\n",
      "5639       Tanjong,CIMB, Axiata push FBM KLCI above 1,290\n",
      "5640               Upward trend intact, stock picking key\n",
      "Name: Headline, Length: 5641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.captions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(dataset.X_train, dataset.y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(dataset.X_test)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "\n",
    "report = classification_report(dataset.y_test, prediction_linear, output_dict=True)\n",
    "\n",
    "print('positive: ', report['pos'])\n",
    "print('negative: ', report['neg'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}