{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "spacy_eng = en_core_web_sm.load()\n",
    "data = os.path.join(os.getcwd(),'data_final.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# To map each word to a index, convert string to numerical value\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold):\n",
    "        # freq_threshold check the freq word in text, if 1 , may not important to us\n",
    "        # <UNK> if the word freq appear is less than threshold, it will map to <UNK>\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "\n",
    "    # tokenize the caption [I love coffee] -> [\"i\",\"love\",\"coffee\"]\n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "    # build vocab\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        # count each caption how many times a specific word repeated\n",
    "        # if over the threshold we will include it, else ignore it\n",
    "        frequencies = {}\n",
    "        # start with index 4 because we have include the tagging\n",
    "        idx = 4\n",
    "\n",
    "        #self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\", 4: \"i\"}\n",
    "        #self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3, \"i\":4}\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer_eng(sentence):\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 1\n",
    "\n",
    "                else:\n",
    "                    frequencies[word] += 1\n",
    "                # if the word frequence is we want,(we just need to append 1 times only)\n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1 # store word to next index\n",
    "\n",
    "    # convert text into number\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer_eng(text)\n",
    "\n",
    "\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] # if word is not in library, <UNK>\n",
    "            for token in tokenized_text\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Down', 'Up', nan], dtype=object)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, captions_file, freq_threshold=5):\n",
    "        self.df = pd.read_csv(captions_file)\n",
    "        self.df = self.df.loc[self.df['Price movement'].isin([\"Up\", \"Down\"])]\n",
    "\n",
    "        # Get img, caption columns\n",
    "        self.captions = self.df[\"Headline\"]\n",
    "        self.results = self.df[\"Price movement\"]\n",
    "\n",
    "        # Initialize vocabulary and build vocab\n",
    "        self.vocab = Vocabulary(freq_threshold)\n",
    "        # Send all the caption as list\n",
    "        self.vocab.build_vocabulary(self.captions.tolist())\n",
    "\n",
    "        vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "\n",
    "        self.Y = []\n",
    "        for result in self.results:\n",
    "            tokenizer = {\"Down\": 0, \"Up\": 1}\n",
    "            self.Y.append(tokenizer[result])\n",
    "\n",
    "        self.captions_train, self.captions_test, self.y_train, self.y_test = train_test_split(self.captions, self.Y,test_size=0.2)\n",
    "\n",
    "        self.X_train = vectorizer.fit_transform(self.captions_train)\n",
    "        self.X_test = vectorizer.transform(self.captions_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.3437724150971783\n",
      "  (0, 202)\t0.3560424120383173\n",
      "  (0, 52)\t0.4525160743373893\n",
      "  (0, 80)\t0.40976245696498775\n",
      "  (0, 75)\t0.42843848566862414\n",
      "  (0, 132)\t0.23064933959392808\n",
      "  (0, 194)\t0.3816013691266663\n",
      "  (1, 99)\t0.17953753105774062\n",
      "  (1, 139)\t0.3431451938337875\n",
      "  (1, 76)\t0.31845504847688344\n",
      "  (1, 15)\t0.19877095874241008\n",
      "  (1, 112)\t0.4191902027652396\n",
      "  (1, 16)\t0.31500864364001885\n",
      "  (1, 91)\t0.31845504847688344\n",
      "  (1, 106)\t0.31845504847688344\n",
      "  (1, 79)\t0.14099705485292277\n",
      "  (1, 116)\t0.287018794233038\n",
      "  (1, 30)\t0.3592437525794593\n",
      "  (2, 19)\t0.47076089769887963\n",
      "  (2, 190)\t0.37213959204021657\n",
      "  (2, 23)\t0.4532299081908088\n",
      "  (2, 3)\t0.43840766775893425\n",
      "  (2, 150)\t0.4922170947919313\n",
      "  (3, 190)\t0.2603388153927634\n",
      "  (3, 163)\t0.6157862496027687\n",
      "  :\t:\n",
      "  (486, 132)\t0.22890187766290873\n",
      "  (486, 15)\t0.21294770270438973\n",
      "  (486, 31)\t0.3305499300906309\n",
      "  (486, 102)\t0.3987414234337518\n",
      "  (486, 155)\t0.37871025369339556\n",
      "  (486, 42)\t0.2835943807180891\n",
      "  (486, 2)\t0.2835943807180891\n",
      "  (486, 84)\t0.3578358174842294\n",
      "  (486, 35)\t0.4490876898708606\n",
      "  (487, 79)\t0.14060055685657605\n",
      "  (487, 192)\t0.1755959401420332\n",
      "  (487, 21)\t0.37114902812170664\n",
      "  (487, 110)\t0.39576974228961365\n",
      "  (487, 126)\t0.36442188997610175\n",
      "  (487, 144)\t0.2962014558357526\n",
      "  (487, 147)\t0.35823352276830184\n",
      "  (487, 45)\t0.3866635451521563\n",
      "  (487, 145)\t0.39576974228961365\n",
      "  (488, 79)\t0.304634139898646\n",
      "  (488, 192)\t0.3804573708013768\n",
      "  (488, 14)\t0.5376287628373232\n",
      "  (488, 78)\t0.6880447246953684\n",
      "  (489, 14)\t1.0\n",
      "  (490, 16)\t0.6216819470450848\n",
      "  (490, 67)\t0.7832697853985128\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.012994s; Prediction time: 0.002003s\n",
      "Accuracy:  0.4715447154471545\n",
      "Up:  {'precision': 0.4727272727272727, 'recall': 0.41935483870967744, 'f1-score': 0.4444444444444444, 'support': 62}\n",
      "Down:  {'precision': 0.47058823529411764, 'recall': 0.5245901639344263, 'f1-score': 0.49612403100775193, 'support': 61}\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(dataset.X_train, dataset.y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(dataset.X_test)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "\n",
    "report = classification_report(dataset.y_test, prediction_linear, output_dict=True)\n",
    "\n",
    "print('Accuracy: ', report['accuracy'])\n",
    "print('Up: ', report['1'])\n",
    "print('Down: ', report['0'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}